model:
  # deepspeed を用いる場合は、重みの配置を deepspeed に任せるので auto は設定しない
  # device_map: auto
  trust_remote_code: true
  torch_dtype: torch.float16

lora:
  r: 4
  lora_alpha: 2
  target_modules:
    # for GPT-NEOX (includes databricks/dolly-v2-xx, cyberagent/open-calm-xx)
    - query_key_value
    - dense
    - dense_h_to_4h
    - dense_4h_to_h
    # for llama
    # - k_proj
    # - v_proj
    # - q_proj
    # - o_proj
    # - gate_proj
    # - up_proj
    # - down_proj
  lora_dropout: 0.01
  bias: none
  task_type: CAUSAL_LM

training:
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 1
  num_train_epochs: 1
  fp16: false
  optim: "adamw_torch"
  learning_rate: 1.0e-4
  logging_steps: 10
  evaluation_strategy: "steps"
  save_strategy: "steps"
  eval_steps: 10
  save_steps: 10
  save_total_limit: 3
  deepspeed: ds_config/ds_config_zero3.json

# early stopping をしない場合はコメントアウトする
early_stopping_callback:
  early_stopping_patience: 5

dataset:
  path: kunishou/databricks-dolly-15k-ja

prompt_template: |-
  ### Instruction:
  {instruction}
  ### Input:
  {input}
  ### Response:
  {output}

# モデルの出力先
outputs:
  dirname: /scratch/${USER}/models/${JOB_ID}


